# Домашнее задание к занятию 17 «Инцидент-менеджмент»

## Основная часть

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

## Ответ


С 21 октября 22:51 UTC были недоступны часть сервисов на протяжении 24 часов 11 минут.
В частности были недоступны webhook, создание и публикация сайтов GitHub Pages.
Пользовательские данные не пострадали.

21 октября в 22:52 проводились работы по устранению неисправности в работе сетевого оптического оборудования, что привело к потере связи на 43 секунды между 2-мя дата-центрами компании.
Данные перерыв связи привел к последовательности негативных событий, которые вызвали перерыв в работе сервиса.

Причинами инцидента стало повреждение репликации баз данных вследствие краткосрочного пропадания связи.
Хранения данных на разных кластерах с существовавшие настройки оркестратора привели к нарушению консистентности данных. 
Кластеры базы данных в дата-центрах на Западном и Восточном побережьях содержали информацию, которой не было в другом, что не позволило безопасно (без потери данных) переключиться на первичный сервер на Восточном побережье.

### Хронология событий

21.10.2018 22:52 UTC
Во время перерыва связи Оркестратор начал процедуру смены лидера и переключил первичную запись в режиме fail over на кластер Западного побережья.
После возобновления связи, приложение начало запись напрямую в дата-центр Западного побережья.
В то же время дата-центр Восточного побережья содержал записи за небольшой промежуток времени, которые не были реплицированы.
Т.о. два дата-центра содержали записи, которые не присутствовали в другом, что не позволяло безопасно без потери данных переключиться на основной дата-центр на Восточном побережье.  


22.10.2018 22:54
Внутренняя система мониторинга начала генерировать алерты многочисленных ошибок.
В 22:02 инженеры первой линии определили, сто кластер находится в некорректном состоянии.
Запрос к API оркестратора показал топологию репликации баз данных только в дата-центре Западного побережья.

22.10.2018 23:07
Ответственная команда вручную заблокировала возможность изменений внутренними инструментами.
В 23:09 сайту был присвоен желтый уровень, что привело к автоматической отправке уведмления координатору инцидента.
В 23:11 координатор инцидента перевел статус сайта в красный уровень.

21.10.2018 23:13
К инциденту подключились дополнительные инженеры, которые исследовали текущее состояние и определяли, какие действия необходимо предпринять, чтобы вручную перевести основную БД в дата-центре на Восточном побережье. 
Это было непросто, поскольку к этому времени в дата-центр на Западном побережье велась запись на протяжении почти 40 минут, в то же время в дата-центре на Восточном побережье имелись записи за несколько секунд. которые препятствовали переключение на него.  
Простое переключение на дата-центр Восточного побережья привело бы к потере более записей за более, чем 30 минут из дата-центра Восточного побережья.
В результате было принято решение для сохранения данных несмотря на ухудшение качества сервиса.


21.10.2018 23:19
Для сохранения данных были остановлены часть сервисов, такие как Webhook и сборка GitHub Pages.
На данный момент основное внимание уделялось сохранности данных, а не удобству использования сайта или сокращению времени восстановления.

22.10.2018 00:05
Инженеры начали разрабатывать план для исправления неконсистентности данных и применение процедуры failover для серверов MySQL.
План заключался в восстановлении из резервной копии и последующей синхронизации в обоих сайтах, востановить топологию и обработать задания из очереди. 
Был обновлен статус инцидента для информирования пользователей.
Резервные копии делались каждые 4 часа и размещались на публичных облачныхх сервисах.
Большой объем данных для восстановления занял несколько часов.
Несмотря на то, что данная процедура тестировалась ежедневно, до этого момента в реальной практике в таком объеме она никогда не использовалась. 

22.10.2018 00:41
Запущен процесс резервного копирования затронутых серверов.
Параллельно часть инженеров искали путь безопасного ускорения передачи данных для восстановления.

22.10.2018 06:51
Инженеры восстановили из резервной копии данные в дата-центре на Восточном побережье и запустили процедуру репликации данных из дата-центра на Западном побережье.
На основании скорости репликации было рассчитано ожидаемое время восстновления - 2 часа. 


22.10.2018 07:46
Опубликовано сообщение в блоге для информирования пользователей о ситуации и извинения. 

22.10.2018 11:12
Все первичные базы данных в дата-центре Восточного побережья были восстановлены, что положительно сказалость на скорости отклика сайта. 
Но еще оставались десятки реплик только для чтения с устаревшей информацией, что приводило к выдаче противоречивых данных пользователям.
Из-за возросшей нагрузки в связи с началом рабочего дгя, скорость восстановления значительно уменьшилась.


22.10.2018 13:15
В связи с высокой нагрузкой пользовательского трафика задержки репликации увеличивались.
Было принято решение создать несколько реплик для чтения в дата-центре Восточного побережья.
После их создания часть трафика перераспределилось на них, что позволило сократить задержки репликации.

22.10.2018 16:24
После синхронизации всех реплик топология была переведена в исходное состояние.
С целью сохранности данных, статус сервиса был сохранен красным.

22.10.2018 16:45
На текущий момент основной задачей было сохранение баланса между работой сервиса и накопленными заданиями.
После начала обработки заданий было обнаружено ~200000 webhook и истекшим TTL.
Обработка была приостановлена, чтобы увеличить TTL.

После возобновления обработки, статус сервиса сохранялся Degraded до окончания полной обработки всех данных и получение уверенности, что сервис работает на нормальном уровне.

22.10.2018 23:03
Все данные были обработаны, целостность данных и нормальная работа сервиса были подтверждены.
Статус сервиса обновлен на зеленый.


### Дальнейшие действия.

#### Исправление неконсистентности данных
После восстановления сервиса был проведен ручной анализ лога MsSql, были обнаружены нереплицированные данныы.
Был произведен анализ на предмет того, какие данные могут быть автоматически согласована, а какие потребуют информирования пользователей.
Как было установлено часть данных были повторены пользователями и успешно записаны.

#### Коммуникации
По результатам восстановления было определено не всегда корректное информирование (например, при оценке времени учитывались не все факторы).
В дальнейшем планируется предоставлять информации более точно.

#### Технические инициативы
1. Изменить конфигурацию оркестратора для предотвращения возникновения некорректной топологии.
2. Текущий статус информирования состояния сервиса в целом (красный, желтый, зеленый) не дает полной картины текущего положения дел во время инцидента, поскольку часть сервисов была доступна.
При этом пользователи не имели четкого представления о состоянии каждого конкретного сервиса. В дальнейшем будет отображаться состояние каждого конкретного сервиса.
3. За несколько недель до инцидента начались работы по усовершенствованию отказоустойчивости работы сервиса. Данный инцидент ускорит его реализацию.
4. Будет усилена проактивная работа по тестированию новых решений.

В дальнейшем будет усилена практика по работе со сбоями, а также внедрены методы хаос инжениринга. 

